{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM for grammar error correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9458\n"
     ]
    }
   ],
   "source": [
    "with open(\"cuentos.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text, allowed_special={\"<|endoftext|>\"})\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cuentos.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[   39,   397, 29690,   555]]), tensor([[  397, 29690,   555,    64]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   39,   397, 29690,   555],\n",
      "        [   64,  1569,    89,   555],\n",
      "        [18605,   259,  3529,    13],\n",
      "        [ 2039,  1288, 18605,  2879],\n",
      "        [18605, 29690,  5192,    78],\n",
      "        [31215,   289, 11736,  3971],\n",
      "        [ 1437,    13,  1482,  8591],\n",
      "        [ 3971,  1437,   289,   330]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  397, 29690,   555,    64],\n",
      "        [ 1569,    89,   555, 18605],\n",
      "        [  259,  3529,    13,  2039],\n",
      "        [ 1288, 18605,  2879, 18605],\n",
      "        [29690,  5192,    78, 31215],\n",
      "        [  289, 11736,  3971,  1437],\n",
      "        [   13,  1482,  8591,  3971],\n",
      "        [ 1437,   289,   330,  8836]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding the LLM architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)  # optional projection\n",
    "\n",
    "        return context_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed-forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (B, T) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest logits value\n",
    "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "                      IN\n",
      "==================================================\n",
      "\n",
      "Input text: Hola, soy un\n",
      "Encoded input text: [39, 5708, 11, 17797, 555]\n",
      "encoded_tensor.shape: torch.Size([1, 5])\n",
      "\n",
      "\n",
      "==================================================\n",
      "                      OUT\n",
      "==================================================\n",
      "\n",
      "Output: tensor([[   39,  5708,    11, 17797,   555, 25952, 28417, 22219, 49228, 46430,\n",
      "         28255, 25889, 43156, 30876,  4256]])\n",
      "Output length: 15\n",
      "Output text: Hola, soy un SSL Surely 401ministicignoreり sang Coup occupying promot\n"
     ]
    }
   ],
   "source": [
    "    GPT_CONFIG_124M = {\n",
    "        \"vocab_size\": 50257,     # Vocabulary size\n",
    "        \"context_length\": 1024,  # Context length\n",
    "        \"emb_dim\": 768,          # Embedding dimension\n",
    "        \"n_heads\": 12,           # Number of attention heads\n",
    "        \"n_layers\": 12,          # Number of layers\n",
    "        \"drop_rate\": 0.1,        # Dropout rate\n",
    "        \"qkv_bias\": False        # Query-Key-Value bias\n",
    "    }\n",
    "\n",
    "    torch.manual_seed(123)\n",
    "    model = GPTModel(GPT_CONFIG_124M)\n",
    "    model.eval()  # disable dropout\n",
    "\n",
    "    start_context = \"Hola, soy un\"\n",
    "\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    encoded = tokenizer.encode(start_context)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "\n",
    "    print(f\"\\n{50*'='}\\n{22*' '}IN\\n{50*'='}\")\n",
    "    print(\"\\nInput text:\", start_context)\n",
    "    print(\"Encoded input text:\", encoded)\n",
    "    print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n",
    "\n",
    "    out = generate_text_simple(\n",
    "        model=model,\n",
    "        idx=encoded_tensor,\n",
    "        max_new_tokens=10,\n",
    "        context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    "    )\n",
    "    decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "\n",
    "    print(f\"\\n\\n{50*'='}\\n{22*' '}OUT\\n{50*'='}\")\n",
    "    print(\"\\nOutput:\", out)\n",
    "    print(\"Output length:\", len(out[0]))\n",
    "    print(\"Output text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()\n",
    "\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen = 0\n",
    "    global_step = -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # Calculate loss gradients\n",
    "            optimizer.step()  # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(gpt_config, settings):\n",
    "\n",
    "    torch.manual_seed(123)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ##############################\n",
    "    # Download data if necessary\n",
    "    ##############################\n",
    "\n",
    "    file_path = \"cuentos.txt\"\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()\n",
    "\n",
    "    ##############################\n",
    "    # Initialize model\n",
    "    ##############################\n",
    "\n",
    "    model = GPTModel(gpt_config)\n",
    "    model.to(device)  # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), lr=settings[\"learning_rate\"], weight_decay=settings[\"weight_decay\"]\n",
    "    )\n",
    "\n",
    "    ##############################\n",
    "    # Set up dataloaders\n",
    "    ##############################\n",
    "\n",
    "    # Train/validation ratio\n",
    "    train_ratio = 0.90\n",
    "    split_idx = int(train_ratio * len(text_data))\n",
    "\n",
    "    train_loader = create_dataloader_v1(\n",
    "        text_data[:split_idx],\n",
    "        batch_size=settings[\"batch_size\"],\n",
    "        max_length=gpt_config[\"context_length\"],\n",
    "        stride=gpt_config[\"context_length\"],\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    val_loader = create_dataloader_v1(\n",
    "        text_data[split_idx:],\n",
    "        batch_size=settings[\"batch_size\"],\n",
    "        max_length=gpt_config[\"context_length\"],\n",
    "        stride=gpt_config[\"context_length\"],\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "\n",
    "    ##############################\n",
    "    # Train model\n",
    "    ##############################\n",
    "\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "        model, train_loader, val_loader, optimizer, device,\n",
    "        num_epochs=settings[\"num_epochs\"], eval_freq=5, eval_iter=1,\n",
    "        start_context=\"En el molino\", tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    return train_losses, val_losses, tokens_seen, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.990, Val loss 10.188\n",
      "Ep 1 (Step 000005): Train loss 8.261, Val loss 8.212\n",
      "Ep 1 (Step 000010): Train loss 6.825, Val loss 6.955\n",
      "Ep 1 (Step 000015): Train loss 6.357, Val loss 6.646\n",
      "En el molino                                                  \n",
      "Ep 2 (Step 000020): Train loss 5.931, Val loss 6.517\n",
      "Ep 2 (Step 000025): Train loss 5.829, Val loss 6.468\n",
      "Ep 2 (Step 000030): Train loss 5.863, Val loss 6.402\n",
      "En el molino.                                                 \n",
      "Ep 3 (Step 000035): Train loss 5.676, Val loss 6.297\n",
      "Ep 3 (Step 000040): Train loss 6.743, Val loss 7.142\n",
      "Ep 3 (Step 000045): Train loss 6.108, Val loss 6.533\n",
      "En el molino.                                                 \n",
      "Ep 4 (Step 000050): Train loss 5.622, Val loss 6.408\n",
      "Ep 4 (Step 000055): Train loss 5.168, Val loss 6.317\n",
      "Ep 4 (Step 000060): Train loss 5.385, Val loss 6.104\n",
      "En el molino. El. El. El que de la una. El. Ela. El de la una. El.                         \n",
      "Ep 5 (Step 000065): Train loss 5.282, Val loss 6.043\n",
      "Ep 5 (Step 000070): Train loss 4.689, Val loss 5.807\n",
      "Ep 5 (Step 000075): Train loss 4.321, Val loss 5.718\n",
      "En el molino.                                                 \n",
      "Ep 6 (Step 000080): Train loss 4.530, Val loss 5.625\n",
      "Ep 6 (Step 000085): Train loss 3.772, Val loss 5.551\n",
      "Ep 6 (Step 000090): Train loss 2.975, Val loss 5.510\n",
      "Ep 6 (Step 000095): Train loss 3.354, Val loss 5.418\n",
      "En el molino. El molinero. El – se que no puedo que se hombre la vela más de una de la casa de la vela muy que se hombre en el hombre y le di\n",
      "Ep 7 (Step 000100): Train loss 3.042, Val loss 5.431\n",
      "Ep 7 (Step 000105): Train loss 1.901, Val loss 5.415\n",
      "Ep 7 (Step 000110): Train loss 2.655, Val loss 5.374\n",
      "En el molino. Pero una. El molinero estaba. Pero, no puedo, no pueda. El molinero, no puedo muchos colores. El muchacha le dijo: “�\n",
      "Ep 8 (Step 000115): Train loss 2.052, Val loss 5.387\n",
      "Ep 8 (Step 000120): Train loss 1.623, Val loss 5.397\n",
      "Ep 8 (Step 000125): Train loss 1.291, Val loss 5.442\n",
      "En el molino. El molinero. El molinero estaba. El molinero estaba que había una. El molinero estaba y llegaron al molino. El muchos nada norna muy\n",
      "Ep 9 (Step 000130): Train loss 2.067, Val loss 5.421\n",
      "Ep 9 (Step 000135): Train loss 1.683, Val loss 5.463\n",
      "Ep 9 (Step 000140): Train loss 1.683, Val loss 5.422\n",
      "En el molino. El molinero. El honda y la vela. El molinero estaba. El hombre le dijo: “Yo pueda viejecito con muchacha le dijo todo al pap\n",
      "Ep 10 (Step 000145): Train loss 1.224, Val loss 5.481\n",
      "Ep 10 (Step 000150): Train loss 0.816, Val loss 5.526\n",
      "Ep 10 (Step 000155): Train loss 0.907, Val loss 5.529\n",
      "En el molino. Pero vieron que las semillas de frijol habían crecido en plantitas. El hilo de las plantitas y llegaron al molino. El muchos nietos en las rodillas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    " \"vocab_size\": 50257,\n",
    " \"context_length\": 256,\n",
    " \"emb_dim\": 768,\n",
    " \"n_heads\": 12,\n",
    " \"n_layers\": 12,\n",
    " \"drop_rate\": 0.1,\n",
    " \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "OTHER_SETTINGS = {\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"num_epochs\": 10,\n",
    "        \"batch_size\": 2,\n",
    "        \"weight_decay\": 0.1\n",
    "    }\n",
    "\n",
    "###########################\n",
    "# Initiate training\n",
    "###########################\n",
    "\n",
    "train_losses, val_losses, tokens_seen, model = main(GPT_CONFIG_124M, OTHER_SETTINGS)\n",
    "\n",
    "###########################\n",
    "# After training\n",
    "###########################\n",
    "\n",
    "# Plot results\n",
    "epochs_tensor = torch.linspace(0, OTHER_SETTINGS[\"num_epochs\"], len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
    "plt.savefig(\"loss.pdf\")\n",
    "\n",
    "# Save and load model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " En el molino vida a toieron que lasja! Vengo dos cas\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    " model=model,\n",
    " idx=text_to_token_ids(\"En el molino\", tokenizer),\n",
    " max_new_tokens=15,\n",
    " context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    " top_k=25,\n",
    " temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se podría construir un dataset algo más grande y solo entrenar una epoch, igual también usar un tokenizer solo de español. Aunque no creo que el esfuerzo merezca la pena porque habría que aumentar el context length y eso son ya demasiados parámetros para tener en local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x7f71d1159f30>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    " \"https://raw.githubusercontent.com/rasbt/\"\n",
    " \"LLMs-from-scratch/main/ch05/\"\n",
    " \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 18:24:04.561437: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741199044.609445    1770 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741199044.624095    1770 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-05 18:24:04.745795: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/774M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/774M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/774M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/774M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    " model_size=\"774M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 1280, 'n_head': 20, 'n_layer': 36}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    " \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    " \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    " \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    " \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-large (774M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "\n",
    "NEW_CONFIG.update({\"context_length\": 1024})\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1280)\n",
       "  (pos_emb): Embedding(1024, 1280)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (24): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (25): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (26): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (27): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (28): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (29): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (30): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (31): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (32): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (33): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (34): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (35): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "        \"Right: {right.shape}\"\n",
    "        )\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1280)\n",
       "  (pos_emb): Embedding(1024, 1280)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (24): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (25): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (26): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (27): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (28): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (29): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (30): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (31): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (32): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (33): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (34): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (35): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Hello everyone as usual the update section is very much a work in progress - but have now added an awesome feature: you may now buy\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    " model=gpt,\n",
    " idx=text_to_token_ids(\"Hello everyone\", tokenizer).to(device),\n",
    " max_new_tokens=25,\n",
    " context_size=NEW_CONFIG[\"context_length\"],\n",
    " top_k=50,\n",
    " temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Corrige gramaticalmente el siguiente texto.', 'input': 'Un hombre está fumando y caminando mientras gente arrojaba cosas desde las ventanas. El hombre los evitaba saltando a un lado pero cuando se acerca al encuadre de la cámara un montón de algo, tal vez basura, cae sobre él. Luego, vemos una pantalla negra que dice \"Culo incómodo.\" El hombre mira hacia arriba, luego mira hacia su bolsillo y saca una lata llena de cigarros y cigarrillos y escoge un cigarrillo. Se quita los guantes y procede a tirarlos a la basura y empieza a fumar.\\n\\nSu mirada se encuentra con un niño llorando en el suelo envuelto en una manta y luego una señora que pasea con su bebé en un cochecito se detiene a unos metros de distancia. La pantalla se vuelve negra y dice: \"Disculpe, se le cayó algo\". El hombre intenta poner al bebé, que encontró en el suelo, en el cochecito de la mujer quien fue sorprendida. De una manera muy desagradecida ella sale corriendo y le grita  y hace un gesto para que vuelva con la bebe. De nuevo el hombre deja al bebé en el suelo cuando un oficial policía ve. Así que lo levanta y camina unos metros dentro un callejón donde le pide a un hombre que lo sostenga mientras se arregla el zapato y lo engaña. Huye y se esconde detrás de una pared. \\n\\n \\n\\nEl nuevo hombre cojea con su bastón hacia el mismo cochecito visto anteriormente en la escena y coloca al bebé en el cochecito.\\n\\nSale de la escena sin ser visto por la mujer. \\n\\nEl hombre original (el personaje principal/protagonista) sale de su escondite y ve al oficial de policía de nuevo y con sospecha y apresuramiento se aleja pasando el cochecito donde la mujer nuevamente vio a un niño adicional y ella lo ve de nuevo. Ella le toma un paraguas bastante grande, lo golpea a él por detrás y lo golpea hacia el cochecito. Mientras esto ocurre, el oficial de policía da la vuelta a la esquina y la mujer le dice al oficial que está tratando de deshacerse del bebé. \\n\\n \\n\\nEl hombre agarra al bebé y se sienta en una acera y encuentra una nota debajo de la manta del niño que dice \"Por favor ama y cuida a este niño huérfano\" Su mirada vuelve a encontrarse con el niño, ahora con una sonrisa, y se levanta y sale del marco. Un final aparentemente feliz.', 'output': 'Un hombre está fumando y caminando mientras gente arroja cosas desde las ventanas. El hombre los evitaba saltando a un lado pero cuando se acerca al encuadre de la cámara un montón de algo, tal vez basura, cae sobre él. Luego, vemos una pantalla negra que dice \"Culo incómodo\". El hombre mira hacia arriba, luego mira hacia su bolsillo y saca una lata llena de cigarros y cigarrillos y escoge un cigarrillo. Se quita los guantes y procede a tirarlos a la basura y empieza a fumar.  Su mirada se encuentra con un niño llorando en el suelo, envuelto en una manta, y luego una señora que pasea con su bebé en un cochecito se detiene a unos metros de distancia. La pantalla se vuelve negra y dice: \"Disculpe, se le cayó algo\". El hombre intenta poner al bebé, que encontró en el suelo, en el cochecito de la mujer, que está sorprendida. De una manera muy desagradecida ella sale corriendo y le grita  y hace un gesto para que vuelva con el bebe. De nuevo el hombre deja al bebé en el suelo cuando un oficial policía lo ve. Así que lo levanta y camina unos metros dentro un callejón donde le pide a un hombre que lo sostenga mientras se arregla el zapato y lo engaña. Huye y se esconde detrás de una pared.    El nuevo hombre cojea con su bastón hacia el mismo cochecito visto anteriormente en la escena y coloca al bebé en el cochecito.  Sale de la escena sin ser visto por la mujer.  El hombre original (el personaje principal/protagonista) sale de su escondite y ve al oficial de policía de nuevo y con sospecha y apresuramiento se aleja pasando el cochecito donde la mujer nuevamente vio a un niño adicional y ella lo ve de nuevo. Ella toma un paraguas bastante grande, lo golpea a él por detrás y lo golpea hacia el cochecito. Mientras esto ocurre, el oficial de policía da la vuelta a la esquina y la mujer le dice al oficial que está tratando de deshacerse del bebé.    El hombre agarra al bebé y se sienta en una acera y encuentra una nota debajo de la manta del niño que dice: \"Por favor ama y cuida a este niño huérfano\". Su mirada vuelve a encontrarse con el niño, ahora con una sonrisa, y se levanta y sale del marco. Un final aparentemente feliz.'}\n"
     ]
    }
   ],
   "source": [
    "# Convert to list of dictionaries\n",
    "data = data.apply(lambda row: {\n",
    "    'instruction': 'Corrige gramaticalmente el siguiente texto.',\n",
    "    'input': row['input'],\n",
    "    'output': row['target']\n",
    "}, axis=1).tolist()\n",
    "\n",
    "# Print the result\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 2929\n",
      "Validation set length: 173\n",
      "Test set length: 344\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n",
      "Loaded model: gpt2-small (124M)\n",
      "--------------------------------------------------\n",
      "Initial losses\n",
      "   Training loss: 3.0441708087921144\n",
      "   Validation loss: 2.932476806640625\n",
      "Ep 1 (Step 000000): Train loss 2.885, Val loss 2.876\n",
      "Ep 1 (Step 000005): Train loss 2.675, Val loss 2.633\n",
      "Ep 1 (Step 000010): Train loss 2.490, Val loss 2.519\n",
      "Ep 1 (Step 000015): Train loss 2.340, Val loss 2.436\n",
      "Ep 1 (Step 000020): Train loss 2.323, Val loss 2.378\n",
      "Ep 1 (Step 000025): Train loss 2.213, Val loss 2.341\n",
      "Ep 1 (Step 000030): Train loss 2.192, Val loss 2.307\n",
      "Ep 1 (Step 000035): Train loss 2.231, Val loss 2.287\n",
      "Ep 1 (Step 000040): Train loss 2.140, Val loss 2.265\n",
      "Ep 1 (Step 000045): Train loss 2.196, Val loss 2.245\n",
      "Ep 1 (Step 000050): Train loss 2.110, Val loss 2.225\n",
      "Ep 1 (Step 000055): Train loss 2.188, Val loss 2.201\n",
      "Ep 1 (Step 000060): Train loss 2.140, Val loss 2.179\n",
      "Ep 1 (Step 000065): Train loss 2.177, Val loss 2.165\n",
      "Ep 1 (Step 000070): Train loss 1.904, Val loss 2.145\n",
      "Ep 1 (Step 000075): Train loss 2.017, Val loss 2.134\n",
      "Ep 1 (Step 000080): Train loss 2.030, Val loss 2.120\n",
      "Ep 1 (Step 000085): Train loss 2.048, Val loss 2.110\n",
      "Ep 1 (Step 000090): Train loss 1.938, Val loss 2.093\n",
      "Ep 1 (Step 000095): Train loss 2.003, Val loss 2.082\n",
      "Ep 1 (Step 000100): Train loss 1.898, Val loss 2.068\n",
      "Ep 1 (Step 000105): Train loss 2.004, Val loss 2.055\n",
      "Ep 1 (Step 000110): Train loss 1.945, Val loss 2.046\n",
      "Ep 1 (Step 000115): Train loss 1.924, Val loss 2.035\n",
      "Ep 1 (Step 000120): Train loss 2.030, Val loss 2.026\n",
      "Ep 1 (Step 000125): Train loss 1.880, Val loss 2.013\n",
      "Ep 1 (Step 000130): Train loss 1.896, Val loss 2.003\n",
      "Ep 1 (Step 000135): Train loss 1.892, Val loss 1.994\n",
      "Ep 1 (Step 000140): Train loss 1.937, Val loss 1.997\n",
      "Ep 1 (Step 000145): Train loss 1.854, Val loss 1.986\n",
      "Ep 1 (Step 000150): Train loss 1.900, Val loss 1.976\n",
      "Ep 1 (Step 000155): Train loss 1.878, Val loss 1.969\n",
      "Ep 1 (Step 000160): Train loss 1.927, Val loss 1.963\n",
      "Ep 1 (Step 000165): Train loss 2.017, Val loss 1.955\n",
      "Ep 1 (Step 000170): Train loss 1.802, Val loss 1.946\n",
      "Ep 1 (Step 000175): Train loss 1.842, Val loss 1.941\n",
      "Ep 1 (Step 000180): Train loss 1.900, Val loss 1.937\n",
      "Ep 1 (Step 000185): Train loss 1.839, Val loss 1.930\n",
      "Ep 1 (Step 000190): Train loss 1.817, Val loss 1.928\n",
      "Ep 1 (Step 000195): Train loss 1.842, Val loss 1.923\n",
      "Ep 1 (Step 000200): Train loss 1.941, Val loss 1.916\n",
      "Ep 1 (Step 000205): Train loss 1.901, Val loss 1.917\n",
      "Ep 1 (Step 000210): Train loss 1.813, Val loss 1.915\n",
      "Ep 1 (Step 000215): Train loss 1.799, Val loss 1.907\n",
      "Ep 1 (Step 000220): Train loss 1.872, Val loss 1.901\n",
      "Ep 1 (Step 000225): Train loss 1.796, Val loss 1.890\n",
      "Ep 1 (Step 000230): Train loss 1.781, Val loss 1.885\n",
      "Ep 1 (Step 000235): Train loss 1.859, Val loss 1.879\n",
      "Ep 1 (Step 000240): Train loss 1.752, Val loss 1.877\n",
      "Ep 1 (Step 000245): Train loss 1.755, Val loss 1.869\n",
      "Ep 1 (Step 000250): Train loss 1.811, Val loss 1.864\n",
      "Ep 1 (Step 000255): Train loss 1.743, Val loss 1.856\n",
      "Ep 1 (Step 000260): Train loss 1.743, Val loss 1.851\n",
      "Ep 1 (Step 000265): Train loss 1.832, Val loss 1.851\n",
      "Ep 1 (Step 000270): Train loss 1.760, Val loss 1.848\n",
      "Ep 1 (Step 000275): Train loss 1.821, Val loss 1.845\n",
      "Ep 1 (Step 000280): Train loss 1.816, Val loss 1.839\n",
      "Ep 1 (Step 000285): Train loss 1.771, Val loss 1.838\n",
      "Ep 1 (Step 000290): Train loss 1.740, Val loss 1.833\n",
      "Ep 1 (Step 000295): Train loss 1.790, Val loss 1.831\n",
      "Ep 1 (Step 000300): Train loss 1.732, Val loss 1.828\n",
      "Ep 1 (Step 000305): Train loss 1.838, Val loss 1.819\n",
      "Ep 1 (Step 000310): Train loss 1.723, Val loss 1.822\n",
      "Ep 1 (Step 000315): Train loss 1.755, Val loss 1.812\n",
      "Ep 1 (Step 000320): Train loss 1.723, Val loss 1.807\n",
      "Ep 1 (Step 000325): Train loss 1.791, Val loss 1.804\n",
      "Ep 1 (Step 000330): Train loss 1.765, Val loss 1.798\n",
      "Ep 1 (Step 000335): Train loss 1.643, Val loss 1.793\n",
      "Ep 1 (Step 000340): Train loss 1.712, Val loss 1.791\n",
      "Ep 1 (Step 000345): Train loss 1.821, Val loss 1.786\n",
      "Ep 1 (Step 000350): Train loss 1.739, Val loss 1.787\n",
      "Ep 1 (Step 000355): Train loss 1.692, Val loss 1.783\n",
      "Ep 1 (Step 000360): Train loss 1.659, Val loss 1.781\n",
      "Ep 1 (Step 000365): Train loss 1.738, Val loss 1.776\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Corrige gramaticalmente el siguiente texto.  ### Input: Emma Watson, una actriz, modela y activista de 27 años, nació en París el 15 de abril de 1990 y fue criada en Oxfordshire. Ella es conocida por su trabajo actuando como Hermione en la serie popular de Harry Potter, pero para mí, ella es mucho más que su carrera como actriz . Emma trabaja en una serie de mis películas favoritas, incluyendo The Perks of Being a Wallflower (2012) y Colonia (2015). Esto es impresionante, considerando que desde 2011 a 2014, Watson dividió su tiempo entre trabajar en proyectos cinematográficos y continuó su educación, estudiando en la Universidad de Brown y Worcester College, Oxford. En Mayo del 2014, se graduó de Brown con una licenciatura en literatura inglés y también fue honrada por la academia británica de las artes de la película y de la televisión por ser la artista británico del año. Como feminista, no puedo dejar de amar a Emma Watson y todo lo que representa. Watson ha promovido la educación de las niñas, visitando lugares como Bangladesh y Zambia, para hacerlo. En julio de 2014, fue nombrada Embajadora de Buena Voluntad de la ONU, y en septiembre de ese mismo año, Watson pronunció un discurso en la sede de la ONU en la ciudad de Nueva York para lanzar la campaña de las Naciones Unidas para la Mujer, HeforShe, que aboga por la igualdad de género. El discurso de Watson también llamó al feminismo \"la creencia de que hombres y mujeres deben tener iguales derechos y oportunidades\" y declaró que la percepción de \"odiar al hombre\" es algo que \"tiene que parar.” Además de ser una actriz increíble, Watson tiene un alma hermosa, una mente rica y un corazón de oro. Watson tiene una hermosa de la oportunidad de la oportunidad de la oportunidad de la oportunidad de la oportunidad de la oportunidad de la oportunidad\n",
      "Ep 2 (Step 000370): Train loss 1.796, Val loss 1.769\n",
      "Ep 2 (Step 000375): Train loss 1.801, Val loss 1.768\n",
      "Ep 2 (Step 000380): Train loss 1.662, Val loss 1.762\n",
      "Ep 2 (Step 000385): Train loss 1.760, Val loss 1.757\n",
      "Ep 2 (Step 000390): Train loss 1.645, Val loss 1.758\n",
      "Ep 2 (Step 000395): Train loss 1.737, Val loss 1.751\n",
      "Ep 2 (Step 000400): Train loss 1.704, Val loss 1.751\n",
      "Ep 2 (Step 000405): Train loss 1.655, Val loss 1.749\n",
      "Ep 2 (Step 000410): Train loss 1.708, Val loss 1.748\n",
      "Ep 2 (Step 000415): Train loss 1.700, Val loss 1.743\n",
      "Ep 2 (Step 000420): Train loss 1.582, Val loss 1.741\n",
      "Ep 2 (Step 000425): Train loss 1.622, Val loss 1.739\n",
      "Ep 2 (Step 000430): Train loss 1.593, Val loss 1.736\n",
      "Ep 2 (Step 000435): Train loss 1.702, Val loss 1.736\n",
      "Ep 2 (Step 000440): Train loss 1.637, Val loss 1.733\n",
      "Ep 2 (Step 000445): Train loss 1.636, Val loss 1.730\n",
      "Ep 2 (Step 000450): Train loss 1.712, Val loss 1.726\n",
      "Ep 2 (Step 000455): Train loss 1.587, Val loss 1.726\n",
      "Ep 2 (Step 000460): Train loss 1.534, Val loss 1.721\n",
      "Ep 2 (Step 000465): Train loss 1.631, Val loss 1.724\n",
      "Ep 2 (Step 000470): Train loss 1.634, Val loss 1.723\n",
      "Ep 2 (Step 000475): Train loss 1.654, Val loss 1.720\n",
      "Ep 2 (Step 000480): Train loss 1.791, Val loss 1.720\n",
      "Ep 2 (Step 000485): Train loss 1.600, Val loss 1.712\n",
      "Ep 2 (Step 000490): Train loss 1.659, Val loss 1.716\n",
      "Ep 2 (Step 000495): Train loss 1.585, Val loss 1.707\n",
      "Ep 2 (Step 000500): Train loss 1.659, Val loss 1.706\n",
      "Ep 2 (Step 000505): Train loss 1.598, Val loss 1.706\n",
      "Ep 2 (Step 000510): Train loss 1.570, Val loss 1.702\n",
      "Ep 2 (Step 000515): Train loss 1.652, Val loss 1.700\n",
      "Ep 2 (Step 000520): Train loss 1.749, Val loss 1.700\n",
      "Ep 2 (Step 000525): Train loss 1.535, Val loss 1.696\n",
      "Ep 2 (Step 000530): Train loss 1.627, Val loss 1.693\n",
      "Ep 2 (Step 000535): Train loss 1.580, Val loss 1.688\n",
      "Ep 2 (Step 000540): Train loss 1.523, Val loss 1.685\n",
      "Ep 2 (Step 000545): Train loss 1.595, Val loss 1.682\n",
      "Ep 2 (Step 000550): Train loss 1.599, Val loss 1.675\n",
      "Ep 2 (Step 000555): Train loss 1.693, Val loss 1.676\n",
      "Ep 2 (Step 000560): Train loss 1.690, Val loss 1.674\n",
      "Ep 2 (Step 000565): Train loss 1.622, Val loss 1.670\n",
      "Ep 2 (Step 000570): Train loss 1.508, Val loss 1.669\n",
      "Ep 2 (Step 000575): Train loss 1.543, Val loss 1.665\n",
      "Ep 2 (Step 000580): Train loss 1.637, Val loss 1.666\n",
      "Ep 2 (Step 000585): Train loss 1.581, Val loss 1.660\n",
      "Ep 2 (Step 000590): Train loss 1.520, Val loss 1.657\n",
      "Ep 2 (Step 000595): Train loss 1.608, Val loss 1.655\n",
      "Ep 2 (Step 000600): Train loss 1.583, Val loss 1.650\n",
      "Ep 2 (Step 000605): Train loss 1.605, Val loss 1.648\n",
      "Ep 2 (Step 000610): Train loss 1.584, Val loss 1.647\n",
      "Ep 2 (Step 000615): Train loss 1.560, Val loss 1.645\n",
      "Ep 2 (Step 000620): Train loss 1.508, Val loss 1.642\n",
      "Ep 2 (Step 000625): Train loss 1.611, Val loss 1.646\n",
      "Ep 2 (Step 000630): Train loss 1.506, Val loss 1.648\n",
      "Ep 2 (Step 000635): Train loss 1.561, Val loss 1.638\n",
      "Ep 2 (Step 000640): Train loss 1.587, Val loss 1.635\n",
      "Ep 2 (Step 000645): Train loss 1.529, Val loss 1.633\n",
      "Ep 2 (Step 000650): Train loss 1.510, Val loss 1.632\n",
      "Ep 2 (Step 000655): Train loss 1.555, Val loss 1.629\n",
      "Ep 2 (Step 000660): Train loss 1.542, Val loss 1.626\n",
      "Ep 2 (Step 000665): Train loss 1.594, Val loss 1.624\n",
      "Ep 2 (Step 000670): Train loss 1.585, Val loss 1.626\n",
      "Ep 2 (Step 000675): Train loss 1.535, Val loss 1.620\n",
      "Ep 2 (Step 000680): Train loss 1.504, Val loss 1.622\n",
      "Ep 2 (Step 000685): Train loss 1.467, Val loss 1.620\n",
      "Ep 2 (Step 000690): Train loss 1.569, Val loss 1.616\n",
      "Ep 2 (Step 000695): Train loss 1.527, Val loss 1.618\n",
      "Ep 2 (Step 000700): Train loss 1.496, Val loss 1.619\n",
      "Ep 2 (Step 000705): Train loss 1.617, Val loss 1.615\n",
      "Ep 2 (Step 000710): Train loss 1.508, Val loss 1.617\n",
      "Ep 2 (Step 000715): Train loss 1.617, Val loss 1.615\n",
      "Ep 2 (Step 000720): Train loss 1.564, Val loss 1.611\n",
      "Ep 2 (Step 000725): Train loss 1.563, Val loss 1.611\n",
      "Ep 2 (Step 000730): Train loss 1.522, Val loss 1.610\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Corrige gramaticalmente el siguiente texto.  ### Input: Emma Watson, una actriz, modela y activista de 27 años, nació en París el 15 de abril de 1990 y fue criada en Oxfordshire. Ella es conocida por su trabajo actuando como Hermione en la serie popular de Harry Potter, pero para mí, ella es mucho más que su carrera como actriz . Emma trabaja en una serie de mis películas favoritas, incluyendo The Perks of Being a Wallflower (2012) y Colonia (2015). Esto es impresionante, considerando que desde 2011 a 2014, Watson dividió su tiempo entre trabajar en proyectos cinematográficos y continuó su educación, estudiando en la Universidad de Brown y Worcester College, Oxford. En Mayo del 2014, se graduó de Brown con una licenciatura en literatura inglés y también fue honrada por la academia británica de las artes de la película y de la televisión por ser la artista británico del año. Como feminista, no puedo dejar de amar a Emma Watson y todo lo que representa. Watson ha promovido la educación de las niñas, visitando lugares como Bangladesh y Zambia, para hacerlo. En julio de 2014, fue nombrada Embajadora de Buena Voluntad de la ONU, y en septiembre de ese mismo año, Watson pronunció un discurso en la sede de la ONU en la ciudad de Nueva York para lanzar la campaña de las Naciones Unidas para la Mujer, HeforShe, que aboga por la igualdad de género. El discurso de Watson también llamó al feminismo \"la creencia de que hombres y mujeres deben tener iguales derechos y oportunidades\" y declaró que la percepción de \"odiar al hombre\" es algo que \"tiene que parar.” Además de ser una actriz increíble, Watson tiene un alma hermosa, una mente rica y un corazón de oro. En la escuela, Watson tiene una hermosa hermosa, una hermosa hermosa, una hermosa hermosa, una hermosa hermosa, una hermosa\n",
      "Training completed in 10.47 minutes.\n",
      "--------------------------------------------------\n",
      "Generating responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 344/344 [17:57<00:00,  3.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses saved as instruction-data-with-response-standalone.json\n",
      "Model saved as gpt2-small124M-sft-standalone.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functools import partial\n",
    "from gpt_download import download_and_load_gpt2\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(50*\"-\")\n",
    "\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "#######################################\n",
    "# Load pretrained model\n",
    "#######################################\n",
    "\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "print(\"Loaded model:\", CHOOSE_MODEL)\n",
    "print(50*\"-\")\n",
    "\n",
    "#######################################\n",
    "# Finetuning the model\n",
    "#######################################\n",
    "print(\"Initial losses\")\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"   Training loss:\", train_loss)\n",
    "print(\"   Validation loss:\", val_loss)\n",
    "\n",
    "start_time = time.time()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
    "print(50*\"-\")\n",
    "\n",
    "#######################################\n",
    "# Saving results\n",
    "#######################################\n",
    "print(\"Generating responses\")\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "test_data_path = \"instruction-data-with-response-standalone.json\"\n",
    "with open(test_data_path, \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing\n",
    "print(f\"Responses saved as {test_data_path}\")\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft-standalone.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk) (4.67.1)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m140.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nltk\n",
      "Successfully installed nltk-3.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "# Ensure the required tokenizer is downloaded\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "def calculate_gleu_score(predictions, references, language='spanish'):\n",
    "    \"\"\"\n",
    "    Calcula el puntaje GLEU promedio para párrafos en español, dividiéndolos en oraciones.\n",
    "\n",
    "    predictions: Lista de párrafos generados por el modelo.\n",
    "    references: Lista de párrafos reales (referencias).\n",
    "    language: Idioma para la tokenización (por defecto, 'spanish').\n",
    "\n",
    "    Retorna: Puntaje GLEU promedio entre las oraciones de los párrafos.\n",
    "    \"\"\"\n",
    "    gleu_scores = []\n",
    "\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        # Dividir los párrafos en oraciones usando el idioma especificado\n",
    "        pred_sentences = nltk.sent_tokenize(pred.lower(), language=language)\n",
    "        ref_sentences = nltk.sent_tokenize(ref.lower(), language=language)\n",
    "\n",
    "        # Alinear y calcular el GLEU por oración\n",
    "        min_len = min(len(pred_sentences), len(ref_sentences))\n",
    "\n",
    "        for i in range(min_len):\n",
    "            pred_tokens = nltk.word_tokenize(pred_sentences[i], language=language)\n",
    "            ref_tokens = nltk.word_tokenize(ref_sentences[i], language=language)\n",
    "\n",
    "            # Calcular el GLEU para cada oración alineada\n",
    "            gleu = sentence_gleu([ref_tokens], pred_tokens)\n",
    "            gleu_scores.append(gleu)\n",
    "\n",
    "    # Retornar el promedio del GLEU (0.0 si no hay puntajes)\n",
    "    return sum(gleu_scores) / len(gleu_scores) if gleu_scores else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Cargar el JSON desde el archivo\n",
    "with open('instruction-data-with-response-standalone.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extraer los campos en listas\n",
    "references = [item[\"output\"] for item in data]\n",
    "predictions = [item[\"model_response\"] for item in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Había trabajado mucho y yo necesito una vacación perfecta. Pienso que una vacación perfecta es en un lugar nuevo. Me gusta aprender sobre historia y hablar con personas nuevas. Quiero ver a las edificios viejos y visitar museos. Los museos que están cerca de mí en Sacramento son sobre instrumentos de medical, trenes y la historia de Sacramento. Quiero aprender sobre una cultura nueva y sus costumbres.                Me gusta comer también. Estoy curiosa sobre la comida de esta cultura. Me gusta comida mexicana, italiana, americana, y japón. Me gusta comer tacos, burritos, sushi, ensaladas de pollo, y otras comidas. No quiero cocinar su comida porque soy'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLEU Score:  0.4849584071851231\n"
     ]
    }
   ],
   "source": [
    "gleu_score = calculate_gleu_score(predictions, references)\n",
    "print(\"GLEU Score: \", gleu_score)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
